qplot(months, temp, data=dtemp, group=city, color=city, geom="line") +
geom_point(size=1.1) +
theme_hc(bgcolor = "darkunica") +
scale_fill_hc("darkunica")
qplot(carat, price, data = dsamp, colour = cut)
+ theme_hc()
+ scale_colour_hc()
qplot(carat, price, data = dsamp, colour = cut)
+theme_hc()+scale_colour_hc()
qplot(carat, price, data = dsamp, colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds[1:100,], colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds[1:1000,], colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_few()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_few()+scale_colour_stata()
qplot(carat, price, data = diamonds, colour=clarity)+theme_few()+scale_colour_stata()
qplot(carat, price, data = diamonds[sample(nrow(diamonds), 1000), ], colour=clarity)+theme_few()+scale_colour_stata()
qplot(carat, price, data = diamonds[sample(nrow(diamonds), 1000), ], colour=clarity)+theme_few()+scale_colour_fivethirtyeight()
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_fivethirtyeight()
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_few()
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_economist()
ggs_autocorrelation(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_economist()
ggs_autocorrelation(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_economist()+scale_fill_economist()
require(ggplot2)
#to get ggthemes from jrnold github if you have not installed
#require(devtools)
#install_github("ggthemes","jrnold")
require(ggthemes)
require(reshape2)
require(directlabels)
require(quantmod)
require(PerformanceAnalytics)
tckrs <- c("CSCO","MSFT","AAPL","^GSPC")
getSymbols(tckrs,from="1990-01-01")
prices <- na.omit(merge(CSCO[,6],MSFT[,6],AAPL[,6],GSPC[,6]))
colnames(prices) <- c("Cisco","Microsoft","Apple","SP500")
returns <- prices/lag(prices) - 1
returns[1,] <- 0
cumul <- cumprod(returns+1)
cumul.df <- as.data.frame(cbind(index(cumul),coredata(cumul)))
cumul.melt <- melt(cumul.df,id.vars=1)
colnames(cumul.melt) <- c("Date","Stock","Cumul")
cumul.melt[,"Date"] <- as.Date(cumul.melt[,"Date"])
direct.label(
ggplot(cumul.melt, aes(x=Date,y=log(Cumul),colour=Stock)) +
geom_line() +
theme_economist() +  #if you want to play try theme_wsj() or theme_few()
scale_colour_economist() +
ggtitle("Apple Compared to Others Since 1990")
, list(last.bumpup,hjust=0.45,cex=0.65))
direct.label(
ggplot(cumul.melt, aes(x=Date,y=log(Cumul),colour=Stock)) +
geom_line() +
theme_economist_white() +  #if you want to play try theme_wsj() or theme_few()
scale_colour_economist() +
ggtitle("Apple Compared to Others Since 1990")
, list(last.bumpup,hjust=0.45,cex=0.65))
#for reference I will use my old favorite theEconomist from latticeExtra
require(latticeExtra)
direct.label(
asTheEconomist(xyplot(log(Cumul)~Date,data=cumul.melt,groups=Stock,
main="Apple Compared to Microsoft and Cisco Since 1990")
)
, list(last.bumpup,hjust=0.25,cex=1))
install.packages("~/Downloads/rjags_4-3.tar", repos = NULL)
install.packages("~/Downloads/rjags_4-3.tar")
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
library(rjags)
install.packages("rjags")
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(rjags)
install.packages("~/Downloads/rjags_4-3-2.tar", repos = NULL)
install.packages("~/Downloads/rjags_4-3-2.tar")
install.packages("~/Downloads/rjags_4-3-2.tar",type="source")
install.packages("~/Downloads/rjags_4-3-2.tar", repos = NULL)
install.packages("~/Downloads/rjags_4-3-2.tar", type="source")
install.packages("~/Downloads/rjags_4-3-2.tar", type="source",repos=NULL)
library("rjags", lib.loc="~/Library/R/3.2/library")
install.packages("~/Downloads/rjags_4-3-2.tar", type="source",repos=NULL,dependencies=TRUE)
library("rjags", lib.loc="~/Library/R/3.2/library")
install.packages("rjags")
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(rjags)
install.packages("~/Downloads/rjags_4-3-2.tar",type="source")
install.packages("rjags")
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
install.packages("coda")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(coda)
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Logit_Mar/script")
# JAGS Code with Adaptive Shrinkage
#  Required libraries
library(rjags);library(ggmcmc);library(ggplot2);library(ggthemes);library(pander);library(Cairo);library(MASS);library(parallel)
library(scales);library(plyr);require(gdata);require(runjags);require(gdata);require(caret);require(pROC);require(plyr)
cl       <- makeCluster(3) # For parallel computing
# Read and format data
data     <- read.csv("..//data/sample_CRP02_sub.csv",header=TRUE,na.strings="")
data[1,]
x<-1
GC_data['x'] <- list(x)
C_data <- vector(mode='list', length = 4)
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data['n'] <- nrow('y')
GC_data['x'] <- list(x)
GC_data
mode(x)
x<-lis(1,21,3)
x<-list(1,21,3)
GC_data['x'] <- x
GC_data['x'] <- list(x)
GC_data['x']
GC_data['x'] <- as.matrix(x)
GC_data['x'] <- as.data.frame(x)
x<-matrix(1,1,1,1,1,1,nrow=2,ncol=2)
x<-matrix(1,1,1,1,nrow=2,ncol=2)
x<-matrix(1,1,1,1,1),nrow=2,ncol=2)
x<-matrix(c(1,1,1,1,1),nrow=2,ncol=2)
matrix(c(1,2,3, 11,12,13), nrow = 2, ncol = 3, byrow = TRUE,
dimnames = list(c("row1", "row2"),
c("C.1", "C.2", "C.3")))
x<-matrix(c(1,2,3, 11,12,13), nrow = 2, ncol = 3, byrow = TRUE,
dimnames = list(c("row1", "row2"),
c("C.1", "C.2", "C.3")))
x
GC_data['x'] <- x
as.data.frame(x)
mode(x)
GC_data['x'] <- x
GC_data
GC_data$x<-x
GC_data
GC_data$x
GC_data <- vector(mode='list', length = 4)
GC_data
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data
Malu_dataset <- read.csv("~/Downloads/Malu_dataset.txt", sep="")
View(Malu_dataset)
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
x<-Malu_dataset
x
x[1,]
x<-x[,c("mag_ab_g", "mag_ab_r", "mag_ab_i","mag_ab_z")]
x
x[1:10,]
y<-x[,6]
y<-Malu_dataset[,6]
y
nrow(y)
GC_data$n <- as.data.frame(y)
GC_data$x <- x
GC_data$y <- list(y)
GC_data$k <- ncol(x)
GC_data
dim(GC_data$y)
GC_data$y
str(GC_data$y)
str(GC_data)
as.numeric(GC_data$y)
as.data.frameGC_data$y
as.data.frame(GC_data$y
)
GC_data$y <- y
as.data.frame(GC_data$y)
mode(y)
library(rstan)
call <- function(x, y, niter=150, warmup=50, chains = 3, model_name = 'lasso') {
#Takes in columns x (independent) and y (dependent), then returns a pystan object with the solution from LASSO.
# --IN--
# x - n by k matrix
# y - n by 1 column
# niter - total number of iterations
# warmup - total amount of warmup iterations (out of total iterations)
# chains - MCMC chains
#--OUT--
# file - pystan object containing results.
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data$n <- as.data.frame(y)
GC_data$x <- x
GC_data$y <- y
GC_data$k <- ncol(x)
#if (e != None){
# print('Errors are not implimented yet.')
#}
modeldir <- '../stan_models/'
modelname <- paste(modeldir,model_name, sep = '')
model <- readChar(modelname,file.info(modelname)$size)
return(stan(model_code = model, data = GC_data, iter = niter, warmup = warmup, chains = chains))
}
call <- function(x, y, niter=150, warmup=50, chains = 3, model_name = 'lasso') {
#Takes in columns x (independent) and y (dependent), then returns a pystan object with the solution from LASSO.
# --IN--
# x - n by k matrix
# y - n by 1 column
# niter - total number of iterations
# warmup - total amount of warmup iterations (out of total iterations)
# chains - MCMC chains
#--OUT--
# file - pystan object containing results.
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data$n <- as.data.frame(y)
GC_data$x <- x
GC_data$y <- y
GC_data$k <- ncol(x)
#if (e != None){
# print('Errors are not implimented yet.')
#}
modeldir <- '../stan_models/'
modelname <- paste(modeldir,model_name, sep = '')
model <- readChar(modelname,file.info(modelname)$size)
return(stan(model_code = model, data = GC_data, iter = niter, warmup = warmup, chains = chains))
}
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/GLM_AGN/script")
require(plyr)
library(caret)
require(kernlab)
library(e1071)
require(MASS)
require(mclust)
AGN_data<-read.table("../data/outputdata_all.txt",header=TRUE,sep="")
AGN_data[1,]
